{"cells":[{"cell_type":"markdown","metadata":{"id":"K1_WKdcrI6w3"},"source":["# Getting started with PPO and ProcGen"]},{"cell_type":"markdown","metadata":{"id":"z7LP1JU3I-d4"},"source":["Here's a bit of code that should help you get started on your projects.\n","\n","The cell below installs `procgen` and downloads a small `utils.py` script that contains some utility functions. You may want to inspect the file for more details."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14392,"status":"ok","timestamp":1609753802554,"user":{"displayName":"Leonardo Zecchin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1QOmj4qqJ2wIz5NDjyksQXdZHmycmtmyBCX2X=s64","userId":"12062207083114703118"},"user_tz":-60},"id":"KdpZ4lmFHtD8","outputId":"b913f3b9-085c-4d0f-9b9a-c975b3327e7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting procgen\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/34/0ae32b01ec623cd822752e567962cfa16ae9c6d6ba2208f3445c017a121b/procgen-0.10.4-cp36-cp36m-manylinux2010_x86_64.whl (39.9MB)\n","\u001b[K     |████████████████████████████████| 39.9MB 83kB/s \n","\u001b[?25hRequirement already satisfied: gym\u003c1.0.0,\u003e=0.15.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (0.17.3)\n","Collecting gym3\u003c1.0.0,\u003e=0.3.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/8c/83da801207f50acfd262041e7974f3b42a0e5edd410149d8a70fd4ad2e70/gym3-0.3.3-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003c2.0.0,\u003e=1.17.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (1.19.4)\n","Requirement already satisfied: filelock\u003c4.0.0,\u003e=3.0.0 in /usr/local/lib/python3.6/dist-packages (from procgen) (3.0.12)\n","Requirement already satisfied: pyglet\u003c=1.5.0,\u003e=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym\u003c1.0.0,\u003e=0.15.0-\u003eprocgen) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym\u003c1.0.0,\u003e=0.15.0-\u003eprocgen) (1.4.1)\n","Requirement already satisfied: cloudpickle\u003c1.7.0,\u003e=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym\u003c1.0.0,\u003e=0.15.0-\u003eprocgen) (1.3.0)\n","Requirement already satisfied: cffi\u003c2.0.0,\u003e=1.13.0 in /usr/local/lib/python3.6/dist-packages (from gym3\u003c1.0.0,\u003e=0.3.3-\u003eprocgen) (1.14.4)\n","Collecting glfw\u003c2.0.0,\u003e=1.8.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/1b/cc758368f1b2466b3701c0f692973aa8a0b51a192a40463c1d02d54d640c/glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203kB)\n","\u001b[K     |████████████████████████████████| 204kB 53.1MB/s \n","\u001b[?25hCollecting moderngl\u003c6.0.0,\u003e=5.5.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/ab/5f72a1b7c5bdbb17160c85e8ba855d48925c74ff93c1e1027d5ad40bf33c/moderngl-5.6.2-cp36-cp36m-manylinux1_x86_64.whl (664kB)\n","\u001b[K     |████████████████████████████████| 665kB 50.3MB/s \n","\u001b[?25hCollecting imageio\u003c3.0.0,\u003e=2.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 56.9MB/s \n","\u001b[?25hCollecting imageio-ffmpeg\u003c0.4.0,\u003e=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/12/01126a2fb737b23461d7dadad3b8abd51ad6210f979ff05c6fa9812dfbbe/imageio_ffmpeg-0.3.0-py3-none-manylinux2010_x86_64.whl (22.2MB)\n","\u001b[K     |████████████████████████████████| 22.2MB 1.2MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet\u003c=1.5.0,\u003e=1.4.0-\u003egym\u003c1.0.0,\u003e=0.15.0-\u003eprocgen) (0.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi\u003c2.0.0,\u003e=1.13.0-\u003egym3\u003c1.0.0,\u003e=0.3.3-\u003eprocgen) (2.20)\n","Collecting glcontext\u003c3,\u003e=2\n","  Downloading https://files.pythonhosted.org/packages/b0/8d/93915df9cd8d31c5f054bbacd1c7a76cd2f776b8212dcc768358bd2d4a37/glcontext-2.2.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio\u003c3.0.0,\u003e=2.6.0-\u003egym3\u003c1.0.0,\u003e=0.3.3-\u003eprocgen) (7.0.0)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug\u003c0.2.7,\u003e=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: glfw, glcontext, moderngl, imageio, imageio-ffmpeg, gym3, procgen\n","  Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","Successfully installed glcontext-2.2.0 glfw-1.12.0 gym3-0.3.3 imageio-2.9.0 imageio-ffmpeg-0.3.0 moderngl-5.6.2 procgen-0.10.4\n","--2021-01-04 09:50:00--  https://raw.githubusercontent.com/nicklashansen/ppo-procgen-utils/main/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14807 (14K) [text/plain]\n","Saving to: ‘utils.py’\n","\n","utils.py            100%[===================\u003e]  14.46K  --.-KB/s    in 0s      \n","\n","2021-01-04 09:50:00 (127 MB/s) - ‘utils.py’ saved [14807/14807]\n","\n"]}],"source":["!pip install procgen\n","!wget https://raw.githubusercontent.com/nicklashansen/ppo-procgen-utils/main/utils.py"]},{"cell_type":"markdown","metadata":{"id":"Bn2rkllGJPtZ"},"source":["Hyperparameters. These values should be a good starting point. You can modify them later once you have a working implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z8P1ehENCwc"},"outputs":[],"source":["# Hyperparameters\n","total_steps = 5e6\n","num_envs = 32\n","num_levels = 100\n","num_steps = 256\n","num_epochs = 3\n","batch_size = 512\n","eps = .2\n","grad_eps = .5\n","value_coef = .5\n","entropy_coef = .1 #.01\n","\n","#####################################\n","n_stack = 3 # =1 for default\n","#####################################"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29416200,"status":"ok","timestamp":1609326987535,"user":{"displayName":"Théo Verdier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinoOOSsrOfwfAZ1ZGqwSWY7uoPqwTvnWP6ilT_Qw=s64","userId":"09513395393035795075"},"user_tz":-60},"id":"yTBV9xpKpEFa"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting to make env\n","Observation space: Box(0.0, 1.0, (9, 64, 64), float32)\n","Action space: 15\n","9\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-dc1fd010eca8\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImpalaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 194\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;31m# Define optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m# these are reasonable values but probably not optimal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m\u003clambda\u003e\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from utils import *# make_env, Storage, orthogonal_init\n","from google.colab import files\n","\n","###############################################################################  \n","def make_env(\n","\tn_envs=32,\n","\tenv_name='bossfight',\n","\tstart_level=0,\n","\tnum_levels=100,\n","\tuse_backgrounds=True,\n","\tnormalize_obs=False,\n","\tnormalize_reward=True,\n","\tseed=0,\n","\n","\t):\n","\t\"\"\"Make environment for procgen experiments\"\"\"\n","\tset_global_seeds(seed)\n","\tset_global_log_levels(40)\n","\tenv = ProcgenEnv(\n","\t\tnum_envs=n_envs,\n","\t\tenv_name=env_name,\n","\t\tstart_level=start_level,\n","\t\tnum_levels=num_levels,\n","\t\tdistribution_mode='easy',\n","\t\tuse_backgrounds=use_backgrounds,\n","\t\trestrict_themes=not use_backgrounds,\n","\t\trender_mode='rgb_array',\n","\t\trand_seed=seed\n","\t)\n","    \n","  \n","\tenv = VecExtractDictObs(env, \"rgb\")\n","\tif n_stack \u003e=2 :\n","\t\tenv = VecFrameStack(env, n_stack)\n","\tenv = VecNormalize(env, ob=normalize_obs, ret=normalize_reward)\n","\tenv = TransposeFrame(env)\n","\tenv = ScaledFloatFrame(env)\n","\tenv = TensorEnv(env)\n","\t\n","\n","\treturn env\n","###############################################################################\n","\n","def random_cutout_color(imgs, min_cut=7,max_cut=22):\n","    \"\"\"\n","        args:\n","        imgs: shape (B,C,H,W)\n","        out: output size (e.g. 84)\n","    \"\"\"\n","    \n","    n, c, h, w = imgs.shape\n","    w1 = np.random.randint(min_cut, max_cut, n)\n","    h1 = np.random.randint(min_cut, max_cut, n)\n","    \n","    cutouts = np.empty((n, c, h, w), dtype=imgs.dtype)\n","    rand_box = np.random.randint(0, 255, size=(n, c)) / 255.\n","    for i, (img, w11, h11) in enumerate(zip(imgs, w1, h1)):\n","        cut_img = img.copy()\n","        \n","        # add random box\n","        cut_img[:, h11:h11 + h11, w11:w11 + w11] = np.tile(\n","            rand_box[i].reshape(-1,1,1),                                                \n","            (1,) + cut_img[:, h11:h11 + h11, w11:w11 + w11].shape[1:])\n","        \n","        cutouts[i] = cut_img\n","    return cutouts\n","\n","def xavier_uniform_init(module, gain=1.0):\n","    if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n","        nn.init.xavier_uniform_(module.weight.data, gain)\n","        nn.init.constant_(module.bias.data, 0)\n","    return module\n","\n","\n","\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size(0), -1)\n","\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self,\n","                 in_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n","\n","    def forward(self, x):\n","        out = nn.ReLU()(x)\n","        out = self.conv1(out)\n","        out = nn.ReLU()(out)\n","        out = self.conv2(out)\n","        return out + x\n","\n","class ImpalaBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ImpalaBlock, self).__init__()\n","        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n","        self.res1 = ResidualBlock(out_channels)\n","        self.res2 = ResidualBlock(out_channels)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)(x)\n","        x = self.res1(x)\n","        x = self.res2(x)\n","        return x\n","\n","class ImpalaModel(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 **kwargs):\n","        super(ImpalaModel, self).__init__()\n","        self.block1 = ImpalaBlock(in_channels=in_channels, out_channels=16)\n","        self.block2 = ImpalaBlock(in_channels=16, out_channels=32)\n","        self.block3 = ImpalaBlock(in_channels=32, out_channels=32)\n","        self.fc = nn.Linear(in_features=32 * 8 * 8, out_features=256)\n","\n","        self.output_dim = 256\n","        self.apply(xavier_uniform_init)\n","\n","    def forward(self, x):\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = nn.ReLU()(x)\n","        x = Flatten()(x)\n","        x = self.fc(x)\n","        x = nn.ReLU()(x)\n","        return x\n","\n","\n","class Encoder(nn.Module):\n","  def __init__(self, in_channels, feature_dim):\n","    super().__init__()\n","    self.layers = nn.Sequential(\n","        nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4), nn.ReLU(),\n","        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), nn.ReLU(),\n","        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1), nn.ReLU(),\n","        Flatten(),\n","        nn.Linear(in_features=1024, out_features=feature_dim), nn.ReLU()\n","    )\n","    self.apply(orthogonal_init)\n","\n","  def forward(self, x):\n","    return self.layers(x)\n","\n","\n","class Policy(nn.Module):\n","  def __init__(self, encoder, feature_dim, num_actions):\n","    super().__init__()\n","    self.encoder = encoder\n","    self.policy = orthogonal_init(nn.Linear(feature_dim, num_actions), gain=.01)\n","    self.value = orthogonal_init(nn.Linear(feature_dim, 1), gain=1.)\n","\n","  def act(self, x):\n","    with torch.no_grad():\n","      x = x.cuda().contiguous()\n","      dist, value = self.forward(x)\n","      action = dist.sample()\n","      log_prob = dist.log_prob(action)\n","    \n","    return action.cpu(), log_prob.cpu(), value.cpu()\n","\n","  def forward(self, x):\n","    x = self.encoder(x)\n","    logits = self.policy(x)\n","    value = self.value(x).squeeze(1)\n","    dist = torch.distributions.Categorical(logits=logits)\n","\n","    return dist, value\n","\n","########################################################################################################################################\n","\n","print(\"starting to make env\")\n","\n","# Define environmentbossfight\n","# check the utils.py file for info on arguments\n","env = make_env(num_envs, num_levels=num_levels, env_name='bossfight')\n","print('Observation space:', env.observation_space)\n","print('Action space:', env.action_space.n)\n","\n","# Define network\n","#encoder = Encoder(3,512)\n","observation_shape = env.observation_space.shape\n","in_channels = observation_shape[0]\n","print(in_channels)\n","encoder = ImpalaModel(in_channels=in_channels)\n","policy = Policy(encoder, 256, 15)\n","policy.cuda()\n","# Define optimizer\n","# these are reasonable values but probably not optimal\n","optimizer = torch.optim.Adam(policy.parameters(), lr=5e-4, eps=1e-5) #lr=5e-4 , eps=1e-5\n","\n","# Define temporary storage\n","# we use this to collect transitions during each iteration\n","storage = Storage(\n","    env.observation_space.shape,\n","    num_steps,\n","    num_envs\n",")\n","\n","\n","# Run training\n","obs = env.reset()\n","step = 0\n","i = 0\n","print(\"NN setup, Training Starts\")\n","while step \u003c total_steps:\n","\n","  # Use policy to collect data for num_steps steps\n","  policy.eval()\n","  for _ in range(num_steps):\n","    # Use policy\n","    action, log_prob, value = policy.act(obs)\n","    \n","    # Take step in environment\n","    next_obs, reward, done, info = env.step(action)\n","\n","    # Store data\n","    storage.store(obs, action, reward, done, info, log_prob, value)\n","    \n","    # Update current observation\n","    obs = next_obs\n","\n","  # Add the last observation to collected data\n","  _, _, value = policy.act(obs)\n","  storage.store_last(obs, value)\n","\n","  # Compute return and advantage\n","  storage.compute_return_advantage()\n","\n","  # Optimize policy\n","  policy.train()\n","  for epoch in range(num_epochs):\n","\n","    # Iterate over batches of transitions\n","    generator = storage.get_generator(batch_size)\n","    for batch in generator:\n","      b_obs, b_action, b_log_prob, b_value, b_returns, b_advantage = batch\n","\n","      ################ data aug ###############\n","      b_obs = random_cutout_color(b_obs.to('cpu').numpy())\n","      b_obs=torch.from_numpy(b_obs).to('cuda')\n","\n","      # Get current policy outputs\n","      new_dist, new_value = policy(b_obs)\n","      new_log_prob = new_dist.log_prob(b_action)\n","      # log_prob\n","      # Clipped policy objective\n","      #print(str(log_prob.shape) + \" \" + str(b_log_prob.shape) + \" \" + str(new_log_prob.shape))\n","      ratio = torch.exp(new_log_prob - b_log_prob)\n","      \n","      clipped_ratio = ratio.clamp(min=1.0 - eps, max=1.0 + eps) \n","      policy_reward = torch.min(ratio * b_advantage, clipped_ratio * b_advantage)\n","      #clip_fraction = (abs((ratio - 1.0)) \u003e clip).to(torch.float).mean()\n","      pi_loss = -policy_reward.mean()\n","\n","      # Clipped value function objective\n","      # clipped_value = new_value + (b_value - new_value).clamp(min=-eps,max=eps)\n","      # vf_loss=torch.max((b_value-b_returns)**2, (clipped_value-b_returns)**2)\n","      # value_loss = 0.5 * vf_loss.mean()\n","\n","      clipped_value = b_value + (new_value - b_value).clamp(min=-eps,max=eps) \n","\n","      clipped_value = (new_value - b_value).clamp(min=-eps,max=eps)\n","      value_loss = 0.5 * torch.max(torch.pow(new_value - b_returns,2), torch.pow(clipped_value - b_returns, 2)).mean()\n","\n","      # Entropy loss\n","      entropy_loss = new_dist.entropy().mean()\n","\n","      # Backpropagate losses\n","      # loss = torch.mean(pi_loss+value_coef*value_loss+entropy_coef*entropy_loss) #\n","      loss = pi_loss + value_coef * value_loss - entropy_coef * entropy_loss\n","      loss.backward()\n","\n","      # Clip gradients\n","      torch.nn.utils.clip_grad_norm_(policy.parameters(), grad_eps)\n","\n","      # Update policy\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","  # Update stats\n","  step += num_envs * num_steps\n","  print(f'Step: {step}\\tMean reward: {storage.get_reward()}')\n","\n","  if step//503808\u003e=i:\n","    torch.save(policy.state_dict(), 'checkpointBoss'+str(i)+'.pt')\n","    files.download('checkpointBoss'+str(i)+'.pt')\n","    i=i+1\n","\n","print('Completed training!')\n","torch.save(policy.state_dict(), 'checkpointBoss_Final.pt')\n","\n","\n","files.download('checkpointBoss_Final.pt')"]},{"cell_type":"markdown","metadata":{"id":"JxRWy_T9JY4M"},"source":["Network definitions. We have defined a policy network for you in advance. It uses the popular `NatureDQN` encoder architecture (see below), while policy and value functions are linear projections from the encodings. There is plenty of opportunity to experiment with architectures, so feel free to do that! Perhaps implement the `Impala` encoder from [this paper](https://arxiv.org/pdf/1802.01561.pdf) (perhaps minus the LSTM)."]},{"cell_type":"markdown","metadata":{"id":"Jp0Rfed3WFU_"},"source":["# New section"]},{"cell_type":"markdown","metadata":{"id":"RAZrWuVGLTu-"},"source":["Below cell can be used for policy evaluation and saves an episode to mp4 for you to view."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"elapsed":29541532,"status":"ok","timestamp":1609327112877,"user":{"displayName":"Théo Verdier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GinoOOSsrOfwfAZ1ZGqwSWY7uoPqwTvnWP6ilT_Qw=s64","userId":"09513395393035795075"},"user_tz":-60},"id":"2zecOCkd7Jzt","outputId":"52b971a6-e7b4-44f1-8bd2-c2583db6fda8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average return: tensor(1.0590)\n"]},{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_fc86068b-b14a-4c2e-a9b5-de4889de98bc\", \"vid_stackBoss.mp4\", 2227724)"],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["import imageio\n","\n","# Make evaluation environment\n","eval_env = make_env(num_envs, env_name = 'bossfight',use_backgrounds=True ,start_level=num_levels, num_levels=num_levels)\n","obs = eval_env.reset()\n","\n","frames = []\n","total_reward = []\n","\n","# Evaluate policy\n","policy.eval()\n","for _ in range(512):\n","\n","  # Use policy\n","  action, log_prob, value = policy.act(obs)\n","\n","  # Take step in environment\n","  obs, reward, done, info = eval_env.step(action)\n","  total_reward.append(torch.Tensor(reward))\n","\n","  # Render environment and store\n","  frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n","  frames.append(frame)\n","\n","# Calculate average return\n","total_reward = torch.stack(total_reward).sum(0).mean(0)\n","print('Average return:', total_reward)\n","\n","# Save frames as video\n","frames = torch.stack(frames).numpy()\n","imageio.mimsave('vid_stackBoss.mp4', frames, fps=25)\n","\n","from google.colab import files\n","files.download('vid_stackBoss.mp4')\n","\n","\n","#\n","#Step: 10006528\tMean reward: 12.428571701049805\n","#Completed training!\n","\n","#Average return: tensor(16.3039)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ImpalaStackDataaug.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}